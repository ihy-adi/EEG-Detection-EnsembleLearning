{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4477,"databundleVersionId":44220,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.layers import (\n    Input, Dense, Conv2D, BatchNormalization, Activation, AveragePooling2D, \n    Dropout, Flatten, Reshape, GlobalAveragePooling2D, LSTM, Bidirectional,\n    Add, LayerNormalization, MultiHeadAttention\n)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom scipy.signal import butter, filtfilt, iirnotch, welch\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nimport matplotlib.pyplot as plt\nimport os\nimport gc\nimport zipfile\nimport glob\nimport re\nimport time\nimport concurrent.futures\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nimport seaborn as sns\n\n# For reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Enable memory growth for GPU\nphysical_devices = tf.config.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    try:\n        for device in physical_devices:\n            tf.config.experimental.set_memory_growth(device, True)\n        print(f\"Found {len(physical_devices)} GPU(s), memory growth enabled\")\n    except Exception as e:\n        print(f\"Error setting memory growth: {e}\")\n\n# Mixed precision\ntry:\n    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n    tf.keras.mixed_precision.set_global_policy(policy)\n    print(f\"Using mixed precision - Compute dtype: {policy.compute_dtype}\")\nexcept:\n    print(\"Mixed precision not available, using default precision\")\n\n# --- Configuration ---\nINPUT_DATA_PATH = '/kaggle/input/grasp-and-lift-eeg-detection'\nWORKING_PATH = '/kaggle/working/'\nOUTPUT_PATH = WORKING_PATH\n\nTRAIN_SERIES = list(range(1, 9))\nVALIDATION_SPLIT_SERIES = [7, 8]\n\nLOW_CUT = 0.5\nHIGH_CUT = 60.0\nFS = 500\n\nWINDOW_SIZE = 400\nWINDOW_OVERLAP = 200\n\nBATCH_SIZE = 128\nMAX_EPOCHS = 40\nINITIAL_LR = 1e-3\nDROPOUT_RATE = 0.5\n\nTARGET_COLS = ['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']\n\n# ------------------ Data Augmentation ---------------------\ndef add_gaussian_noise(X, std=0.01):\n    noise = np.random.normal(0, std, X.shape)\n    return X + noise\n\ndef random_channel_dropout(X, dropout_prob=0.1):\n    X_aug = X.copy()\n    for i in range(X.shape[0]):\n        if np.random.rand() < dropout_prob:\n            ch = np.random.randint(X.shape[1])\n            X_aug[i, ch, ...] = 0\n    return X_aug\n\ndef mixup(X, y, alpha=0.2):\n    idx = np.random.permutation(len(X))\n    l = np.random.beta(alpha, alpha)\n    X_mix = l * X + (1 - l) * X[idx]\n    y_mix = l * y + (1 - l) * y[idx]\n    return X_mix, y_mix\n\n# ---------- Filtering and Feature Extraction -----------------\ndef butter_bandpass_filter_optimized(data, lowcut, highcut, fs, order=5):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    chunk_size = min(10000, data.shape[0])\n    n_samples = data.shape[0]\n    n_channels = data.shape[1]\n    filtered_data = np.zeros_like(data)\n    def filter_chunk(start_idx):\n        end_idx = min(start_idx + chunk_size, n_samples)\n        filtered_chunk = filtfilt(b, a, data[start_idx:end_idx, :], axis=0)\n        return start_idx, filtered_chunk\n    if data.shape[0] > 50000 and n_channels > 16:\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            futures = []\n            for i in range(0, n_samples, chunk_size):\n                futures.append(executor.submit(filter_chunk, i))\n            for future in concurrent.futures.as_completed(futures):\n                start_idx, chunk = future.result()\n                end_idx = min(start_idx + chunk_size, n_samples)\n                filtered_data[start_idx:end_idx, :] = chunk\n    else:\n        for i in range(0, n_samples, chunk_size):\n            start_idx, chunk = filter_chunk(i)\n            end_idx = min(start_idx + chunk_size, n_samples)\n            filtered_data[start_idx:end_idx, :] = chunk\n    return filtered_data\n\ndef apply_notch_filter(data, fs=500, f0=50.0, quality_factor=30.0):\n    nyq = 0.5 * fs\n    w0 = f0 / nyq\n    b, a = iirnotch(w0, quality_factor)\n    chunk_size = min(10000, data.shape[0])\n    n_samples = data.shape[0]\n    filtered_data = np.zeros_like(data)\n    for i in range(0, n_samples, chunk_size):\n        end = min(i + chunk_size, n_samples)\n        filtered_data[i:end] = filtfilt(b, a, data[i:end], axis=0)\n    return filtered_data\n\ndef extract_features_from_window(window):\n    n_samples, n_channels = window.shape\n    means = np.mean(window, axis=0)\n    stds = np.std(window, axis=0)\n    diff1 = np.diff(window, n=1, axis=0)\n    diff2 = np.diff(window, n=2, axis=0)\n    activity = np.var(window, axis=0)\n    mobility_num = np.var(diff1, axis=0)\n    mobility_den = activity.copy()\n    mobility_den[mobility_den == 0] = 1e-10\n    mobility = np.sqrt(mobility_num / mobility_den)\n    complexity_num = np.var(diff2, axis=0)\n    complexity_den = np.var(diff1, axis=0)\n    complexity_den[complexity_den == 0] = 1e-10\n    complexity = np.sqrt(complexity_num / complexity_den) / mobility\n    mobility = np.nan_to_num(mobility)\n    complexity = np.nan_to_num(complexity)\n    downsample_factor = 4\n    downsampled = window[::downsample_factor]\n    fs_downsampled = FS / downsample_factor\n    bands = [(1, 4), (4, 8), (8, 13), (13, 30), (30, 45)]\n    band_powers = np.zeros((n_channels, len(bands)))\n    for ch in range(n_channels):\n        freqs, psd = welch(downsampled[:, ch], fs=fs_downsampled, nperseg=min(256, downsampled.shape[0]))\n        for b, (low, high) in enumerate(bands):\n            idx = np.logical_and(freqs >= low, freqs <= high)\n            band_powers[ch, b] = np.mean(psd[idx]) if np.any(idx) else 0\n    features = np.hstack([\n        means, stds, activity, mobility, complexity, band_powers.flatten()\n    ])\n    return features\n\n# --------------- Data Loading and Windowing -----------------\ndef load_series_data(target_series_ids, data_base_path, is_test=False, downsample_factor=2):\n    all_data = []\n    all_labels = []\n    all_ids = []\n    sub_dir = 'test' if is_test else 'train'\n    full_sub_dir_path = os.path.join(data_base_path, sub_dir)\n    if not os.path.isdir(full_sub_dir_path):\n        raise FileNotFoundError(f\"Directory not found: {full_sub_dir_path}\")\n    print(f\"Loading series {target_series_ids}\")\n    all_files = glob.glob(os.path.join(full_sub_dir_path, 'subj*_series*.csv'))\n    data_files = []\n    event_files = {}\n    for series_id in target_series_ids:\n        data_pattern = re.compile(rf\"subj\\d+_series{series_id}_data\\.csv$\")\n        series_data_files = [f for f in all_files if data_pattern.search(os.path.basename(f))]\n        if not series_data_files:\n            print(f\"Warning: No data files found for series {series_id}\")\n            continue\n        data_files.extend(series_data_files)\n        if not is_test:\n            for data_file in series_data_files:\n                event_file = data_file.replace('_data.csv', '_events.csv')\n                if os.path.exists(event_file):\n                    event_files[data_file] = event_file\n    if not data_files:\n        raise FileNotFoundError(f\"No data files found for any series in {target_series_ids}\")\n    print(f\"Found {len(data_files)} data files\")\n    for data_file in data_files:\n        try:\n            if os.path.getsize(data_file) > 100 * 1024 * 1024:\n                chunks = pd.read_csv(data_file, chunksize=100000)\n                eeg_chunks = []\n                id_chunks = []\n                for chunk in chunks:\n                    eeg_chunks.append(chunk.drop('id', axis=1).values)\n                    id_chunks.append(chunk['id'].values)\n                eeg_data = np.vstack(eeg_chunks)\n                ids = np.concatenate(id_chunks)\n            else:\n                df = pd.read_csv(data_file)\n                ids = df['id'].values\n                eeg_data = df.drop('id', axis=1).values\n            eeg_data = eeg_data[::downsample_factor]\n            ids = ids[::downsample_factor]\n            all_data.append(eeg_data)\n            all_ids.append(ids)\n            if not is_test and data_file in event_files:\n                event_file = event_files[data_file]\n                series_events = pd.read_csv(event_file)\n                labels = np.zeros((len(eeg_data), len(TARGET_COLS)))\n                event_map = {col: i for i, col in enumerate(TARGET_COLS)}\n                id_to_index = {id_val: idx for idx, id_val in enumerate(ids)}\n                for _, row in series_events.iterrows():\n                    event_id = row['id']\n                    if event_id in id_to_index:\n                        idx = id_to_index[event_id]\n                        for event_name in TARGET_COLS:\n                            if event_name in row and row[event_name] == 1:\n                                labels[idx, event_map[event_name]] = 1\n                all_labels.append(labels)\n            elif not is_test:\n                all_labels.append(np.zeros((len(eeg_data), len(TARGET_COLS))))\n            gc.collect()\n        except Exception as e:\n            print(f\"Error processing {data_file}: {e}\")\n    if not all_data:\n        raise ValueError(\"Failed to load any valid data\")\n    concatenated_data = np.vstack(all_data)\n    concatenated_ids = np.concatenate(all_ids)\n    if not is_test and all_labels:\n        concatenated_labels = np.vstack(all_labels)\n    else:\n        concatenated_labels = None if is_test else np.zeros((concatenated_data.shape[0], len(TARGET_COLS)))\n    print(f\"Data loaded and downsampled. Shape: {concatenated_data.shape}\")\n    return concatenated_data, concatenated_labels, concatenated_ids\n\ndef create_windows_with_features(data, labels=None, ids=None, window_size=WINDOW_SIZE, overlap=WINDOW_OVERLAP):\n    print(\"Creating windows with advanced features...\")\n    num_samples, num_channels = data.shape\n    step = window_size - overlap\n    num_windows = max(0, (num_samples - window_size) // step + 1)\n    if num_windows <= 0:\n        print(f\"Not enough samples ({num_samples}) for window size {window_size}\")\n        empty_shape = (0, window_size, num_channels)\n        return (np.array([]).reshape(empty_shape), \n                None if labels is None else np.array([]).reshape((0, labels.shape[1])), \n                np.array([]),\n                np.array([]))\n    print(f\"Creating {num_windows} windows with size {window_size} and step {step}\")\n    windows = np.zeros((num_windows, window_size, num_channels))\n    window_labels = np.zeros((num_windows, labels.shape[1])) if labels is not None else None\n    window_ids = np.zeros(num_windows, dtype=object if ids.dtype == np.dtype('O') else ids.dtype)\n    feature_list = []\n    batch_size = min(1000, num_windows)\n    for batch_start in range(0, num_windows, batch_size):\n        batch_end = min(batch_start + batch_size, num_windows)\n        for i in range(batch_start, batch_end):\n            start_idx = i * step\n            end_idx = start_idx + window_size\n            window = data[start_idx:end_idx, :]\n            windows[i] = window\n            if i % 5 == 0 or i == num_windows - 1:\n                features = extract_features_from_window(window)\n                feature_list.append((i, features))\n            if labels is not None:\n                window_labels[i] = np.max(labels[start_idx:end_idx], axis=0)\n            window_ids[i] = ids[end_idx - 1]\n    feature_indices = [item[0] for item in feature_list]\n    feature_values = [item[1] for item in feature_list]\n    feature_dim = feature_values[0].shape[0]\n    all_features = np.zeros((num_windows, feature_dim))\n    for idx, features in zip(feature_indices, feature_values):\n        all_features[idx] = features\n    for i in range(num_windows):\n        if i not in feature_indices:\n            left_idx = max([idx for idx in feature_indices if idx < i], default=feature_indices[0])\n            right_idx = min([idx for idx in feature_indices if idx > i], default=feature_indices[-1])\n            if left_idx == right_idx:\n                all_features[i] = all_features[left_idx]\n            else:\n                left_weight = (right_idx - i) / (right_idx - left_idx)\n                right_weight = (i - left_idx) / (right_idx - left_idx)\n                all_features[i] = left_weight * all_features[left_idx] + right_weight * all_features[right_idx]\n    print(f\"Created windows shape: {windows.shape}\")\n    print(f\"Extracted features shape: {all_features.shape}\")\n    return windows, window_labels, window_ids, all_features\n\ndef preprocess_data_pipeline(series_ids, data_base_path, scaler=None, is_test=False, augment=False):\n    print(f\"Loading {'test' if is_test else 'training'} data for series {series_ids}...\")\n    raw_data, raw_labels, raw_ids = load_series_data(series_ids, data_base_path, is_test=is_test, downsample_factor=2)\n    if raw_data.shape[0] == 0:\n        print(f\"No data loaded for series {series_ids}\")\n        return np.array([]), None, np.array([]), None, scaler\n    print(\"Applying advanced filters...\")\n    filtered_data = butter_bandpass_filter_optimized(raw_data, LOW_CUT, HIGH_CUT, FS/2)\n    filtered_data = apply_notch_filter(filtered_data, fs=FS/2, f0=50.0 * 2 / FS)\n    del raw_data\n    gc.collect()\n    print(\"Scaling data...\")\n    if scaler is None:\n        scaler = RobustScaler()\n        scaled_data = scaler.fit_transform(filtered_data)\n    else:\n        scaled_data = scaler.transform(filtered_data)\n    del filtered_data\n    gc.collect()\n    print(\"Creating windows and extracting features...\")\n    windows, window_labels, window_ids, features = create_windows_with_features(\n        scaled_data, raw_labels, raw_ids, WINDOW_SIZE, WINDOW_OVERLAP\n    )\n    del scaled_data, raw_labels, raw_ids\n    gc.collect()\n    if windows.shape[0] == 0:\n        print(f\"No windows created for series {series_ids}\")\n        return np.array([]), None, np.array([]), None, scaler\n    n_channels = windows.shape[2]\n    # Data augmentation\n    if augment:\n        # Add noise, dropout, and mixup\n        windows = add_gaussian_noise(windows, std=0.02)\n        windows = random_channel_dropout(windows, dropout_prob=0.15)\n        if window_labels is not None:\n            windows, window_labels = mixup(windows, window_labels, alpha=0.2)\n    windows_reshaped = windows.reshape(windows.shape[0], n_channels, WINDOW_SIZE, 1)\n    if is_test:\n        return windows_reshaped, window_ids, features, None, scaler\n    else:\n        return windows_reshaped, window_labels, window_ids, features, scaler\n\n# ------------------ Model Architectures ---------------------\ndef build_eegnet_tcn(n_channels, window_size, n_outputs=6):\n    inputs = Input(shape=(n_channels, window_size, 1))\n    x = Conv2D(16, (1, 64), padding='same', use_bias=False)(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('elu')(x)\n    x = Conv2D(32, (n_channels, 1), padding='valid', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('elu')(x)\n    x = AveragePooling2D((1, 4))(x)\n    x = Dropout(0.3)(x)\n    for dilation_rate in [1, 2, 4, 8]:\n        res = x\n        x = Conv2D(32, (1, 3), padding='same', dilation_rate=(1, dilation_rate))(x)\n        x = BatchNormalization()(x)\n        x = Activation('elu')(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(32, (1, 3), padding='same')(x)\n        x = BatchNormalization()(x)\n        if res.shape[-1] != x.shape[-1]:\n            res = Conv2D(32, (1, 1), padding='same')(res)\n        x = Add()([res, x])\n        x = Activation('elu')(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation='elu')(x)\n    x = Dropout(DROPOUT_RATE)(x)\n    x = Dense(n_outputs, activation='sigmoid')(x)\n    return Model(inputs=inputs, outputs=x)\n\ndef build_cnn_blstm_model(n_channels, window_size, n_outputs=6, feature_dim=None):\n    eeg_input = Input(shape=(n_channels, window_size, 1), name='eeg_input')\n    x = Conv2D(32, (1, 32), padding='same')(eeg_input)\n    x = BatchNormalization()(x)\n    x = Activation('elu')(x)\n    x = AveragePooling2D((1, 4))(x)\n    x = Conv2D(64, (n_channels, 1), padding='valid')(x)\n    x = BatchNormalization()(x)\n    x = Activation('elu')(x)\n    x = Dropout(0.3)(x)\n    _, c, t, f = x.shape\n    x = Reshape((t, c*f))(x)\n    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n    x = Dropout(0.3)(x)\n    x = Bidirectional(LSTM(32))(x)\n    if feature_dim is not None:\n        feature_input = Input(shape=(feature_dim,), name='feature_input')\n        f_x = Dense(64, activation='elu')(feature_input)\n        f_x = BatchNormalization()(f_x)\n        f_x = Dropout(0.3)(f_x)\n        f_x = Dense(32, activation='elu')(f_x)\n        x = tf.keras.layers.concatenate([x, f_x])\n        x = Dense(128, activation='elu')(x)\n        x = Dropout(DROPOUT_RATE)(x)\n        x = Dense(32, activation='elu')(x)\n        x = Dense(n_outputs, activation='sigmoid')(x)\n        return Model(inputs=[eeg_input, feature_input], outputs=x)\n    else:\n        x = Dense(128, activation='elu')(x)\n        x = Dropout(DROPOUT_RATE)(x)\n        x = Dense(32, activation='elu')(x)\n        x = Dense(n_outputs, activation='sigmoid')(x)\n        return Model(inputs=eeg_input, outputs=x)\n\ndef build_attention_eeg_model(n_channels, window_size, n_outputs=6):\n    # Attention-based EEG model\n    inp = Input(shape=(n_channels, window_size, 1))\n    x = Conv2D(32, (1, 32), padding='same', activation='elu')(inp)\n    x = BatchNormalization()(x)\n    x = Reshape((window_size, n_channels*32))(x)\n    x = LayerNormalization()(x)\n    x = MultiHeadAttention(num_heads=4, key_dim=16)(x, x)\n    x = Flatten()(x)\n    x = Dense(128, activation='elu')(x)\n    x = Dropout(DROPOUT_RATE)(x)\n    out = Dense(n_outputs, activation='sigmoid')(x)\n    return Model(inp, out)\n\n# ------------------ Training and Validation -----------------\ndef train_model_with_features(X_train, y_train, X_val, y_val, features_train=None, features_val=None, model_type='cnn_blstm'):\n    print(f\"\\n--- Building and Training {model_type} Model ---\")\n    n_channels = X_train.shape[1]\n    if model_type == 'eegnet_tcn':\n        model = build_eegnet_tcn(n_channels, WINDOW_SIZE, len(TARGET_COLS))\n        train_data = X_train\n        val_data = X_val\n    elif model_type == 'cnn_blstm':\n        if features_train is not None:\n            feature_dim = features_train.shape[1]\n            model = build_cnn_blstm_model(n_channels, WINDOW_SIZE, len(TARGET_COLS), feature_dim)\n            train_data = [X_train, features_train]\n            val_data = [X_val, features_val]\n        else:\n            model = build_cnn_blstm_model(n_channels, WINDOW_SIZE, len(TARGET_COLS))\n            train_data = X_train\n            val_data = X_val\n    elif model_type == 'attention':\n        model = build_attention_eeg_model(n_channels, WINDOW_SIZE, len(TARGET_COLS))\n        train_data = X_train\n        val_data = X_val\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n    model.compile(\n        optimizer=Adam(learning_rate=INITIAL_LR),\n        loss='binary_crossentropy',\n        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n    )\n    callbacks_list = [\n        ModelCheckpoint(\n            filepath=os.path.join(OUTPUT_PATH, f'best_{model_type}_model.keras'),\n            monitor='val_auc', mode='max', save_best_only=True, verbose=1\n        ),\n        EarlyStopping(\n            monitor='val_auc', mode='max', patience=10, verbose=1, restore_best_weights=True\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss', mode='min', factor=0.5, patience=4, min_lr=1e-6, verbose=1\n        )\n    ]\n    class_weights = None\n    history = model.fit(\n        train_data, y_train,\n        batch_size=BATCH_SIZE,\n        epochs=MAX_EPOCHS,\n        validation_data=(val_data, y_val),\n        callbacks=callbacks_list,\n        class_weight=class_weights,\n        verbose=2\n    )\n    return model, history\n\ndef tta_predict(model, X, features=None, num_aug=5):\n    preds = []\n    for _ in range(num_aug):\n        X_aug = add_gaussian_noise(X, std=0.01)\n        if features is not None:\n            pred = model.predict([X_aug, features], batch_size=BATCH_SIZE*2, verbose=0)\n        else:\n            pred = model.predict(X_aug, batch_size=BATCH_SIZE*2, verbose=0)\n        preds.append(pred)\n    return np.mean(preds, axis=0)\n\ndef train_with_cross_validation(X, y, features=None, n_splits=5):\n    print(f\"\\n--- Training with {n_splits}-Fold Stratified Cross-Validation ---\")\n    # Use stratified CV on the first label (works for multi-label if at least one event per window)\n    y_strat = (y[:, 0] > 0).astype(int)\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    model_types = ['eegnet_tcn', 'cnn_blstm', 'attention']\n    all_val_aucs = []\n    fold_models = []\n    histories = []\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_strat)):\n        print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n        if features is not None:\n            features_train, features_val = features[train_idx], features[val_idx]\n        else:\n            features_train = features_val = None\n        model_type = model_types[fold % len(model_types)]\n        print(f\"Training {model_type} model for fold {fold+1}\")\n        model, history = train_model_with_features(\n            X_train_fold, y_train_fold, X_val_fold, y_val_fold, \n            features_train, features_val, model_type\n        )\n        # TTA for validation\n        if features is not None and model_type == 'cnn_blstm':\n            val_pred = tta_predict(model, X_val_fold, features_val)\n            val_scores = [\n                roc_auc_score((y_val_fold[:, i] > 0.5).astype(int), val_pred[:, i]) if len(np.unique(y_val_fold[:, i])) > 1 else np.nan\n                for i in range(y_val_fold.shape[1])\n            ]\n            val_auc = np.nanmean(val_scores)\n        else:\n            val_pred = tta_predict(model, X_val_fold)\n            val_scores = [\n                roc_auc_score((y_val_fold[:, i] > 0.5).astype(int), val_pred[:, i]) if len(np.unique(y_val_fold[:, i])) > 1 else np.nan\n                for i in range(y_val_fold.shape[1])\n            ]\n            val_auc = np.nanmean(val_scores)\n        print(f\"Fold {fold+1} {model_type} - Validation AUC: {val_auc:.4f}\")\n        all_val_aucs.append(val_auc)\n        fold_models.append((model_type, model))\n        histories.append(history)\n    print(\"\\n--- Cross-Validation Results ---\")\n    for fold, (model_type, _) in enumerate(fold_models):\n        print(f\"Fold {fold+1}: {model_type} - AUC = {all_val_aucs[fold]:.4f}\")\n    print(f\"Average AUC: {np.mean(all_val_aucs):.4f} ± {np.std(all_val_aucs):.4f}\")\n    best_fold = np.argmax(all_val_aucs)\n    best_model_type, best_model = fold_models[best_fold]\n    print(f\"Best model from fold {best_fold+1}: {best_model_type} with AUC {all_val_aucs[best_fold]:.4f}\")\n    return (best_model_type, best_model), fold_models, histories[best_fold]\n\ndef plot_history(history, model_type='model'):\n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 3, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title(f'{model_type} Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='lower right')\n    plt.grid(True)\n    plt.subplot(1, 3, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title(f'{model_type} Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n    plt.grid(True)\n    if 'auc' in history.history:\n        plt.subplot(1, 3, 3)\n        plt.plot(history.history['auc'])\n        plt.plot(history.history['val_auc'])\n        plt.title(f'{model_type} AUC')\n        plt.ylabel('AUC')\n        plt.xlabel('Epoch')\n        plt.legend(['Train', 'Validation'], loc='lower right')\n        plt.grid(True)\n    plt.tight_layout()\n    history_plot_path = os.path.join(OUTPUT_PATH, f'{model_type}_training_history.png')\n    try:\n        plt.savefig(history_plot_path)\n        print(f\"History plot saved to: {history_plot_path}\")\n    except Exception as e:\n        print(f\"Error saving history plot: {e}\")\n    plt.close()\n\n# ----------- Advanced Ensemble with Gradient Boosting --------\ndef ensemble_predictions(preds_list, y_val=None):\n    preds_array = np.stack(preds_list, axis=-1)\n    n_samples, n_outputs, n_models = preds_array.shape\n    meta_preds = np.zeros((n_samples, n_outputs))\n    for i in range(n_outputs):\n        if len(np.unique(y_val[:, i])) > 1:\n            meta_model = HistGradientBoostingClassifier(max_iter=200)\n            meta_model.fit(preds_array[:, i, :], y_val[:, i])\n            meta_preds[:, i] = meta_model.predict_proba(preds_array[:, i, :])[:, 1]\n        else:\n            meta_preds[:, i] = np.mean(preds_array[:, i, :], axis=-1)\n    return meta_preds\n\n#------------ Confusion Matrix ---------------------------------\ndef plot_confusion_matrices(y_true, y_pred, class_names):\n    \"\"\"\n    Plot confusion matrices for all classes\n    \n    Args:\n        y_true: Ground truth labels (one-hot encoded)\n        y_pred: Predicted probabilities\n        class_names: List of class names\n    \"\"\"\n    # Convert probabilities to binary predictions\n    y_pred_binary = (y_pred > 0.5).astype(int)\n    \n    # Create a figure with subplots\n    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n    axes = axes.flatten()\n    \n    # Overall metrics for reporting\n    all_cms = []\n    all_metrics = {\n        'accuracy': [],\n        'precision': [],\n        'recall': [],\n        'f1': []\n    }\n    \n    for i, class_name in enumerate(class_names):\n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true[:, i], y_pred_binary[:, i])\n        all_cms.append(cm)\n        \n        # Calculate metrics\n        acc = accuracy_score(y_true[:, i], y_pred_binary[:, i])\n        prec = precision_score(y_true[:, i], y_pred_binary[:, i], zero_division=0)\n        rec = recall_score(y_true[:, i], y_pred_binary[:, i], zero_division=0)\n        f1 = f1_score(y_true[:, i], y_pred_binary[:, i], zero_division=0)\n        \n        all_metrics['accuracy'].append(acc)\n        all_metrics['precision'].append(prec)\n        all_metrics['recall'].append(rec)\n        all_metrics['f1'].append(f1)\n        \n        # Plot confusion matrix\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n        axes[i].set_title(f'{class_name}\\nAcc: {acc:.4f}, F1: {f1:.4f}')\n        axes[i].set_xlabel('Predicted')\n        axes[i].set_ylabel('True')\n        axes[i].set_xticklabels(['Negative', 'Positive'])\n        axes[i].set_yticklabels(['Negative', 'Positive'])\n    \n    plt.tight_layout()\n    cm_plot_path = os.path.join(OUTPUT_PATH, 'confusion_matrices.png')\n    plt.savefig(cm_plot_path)\n    plt.close()\n    print(f\"Confusion matrices saved to: {cm_plot_path}\")\n    \n    # Return the metrics for reporting\n    return all_cms, all_metrics\n\n# Function to print detailed metrics report\ndef print_metrics_report(metrics, class_names):\n    \"\"\"Print a detailed metrics report\"\"\"\n    print(\"\\n===== Detailed Metrics Report =====\")\n    print(f\"{'Class':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1 Score':<10}\")\n    print(\"-\" * 60)\n    \n    for i, class_name in enumerate(class_names):\n        print(f\"{class_name:<20} {metrics['accuracy'][i]:.4f}     {metrics['precision'][i]:.4f}     \"\n              f\"{metrics['recall'][i]:.4f}     {metrics['f1'][i]:.4f}\")\n    \n    # Print averages\n    print(\"-\" * 60)\n    print(f\"{'Average':<20} {np.mean(metrics['accuracy']):.4f}     {np.mean(metrics['precision']):.4f}     \"\n          f\"{np.mean(metrics['recall']):.4f}     {np.mean(metrics['f1']):.4f}\")\n\n\n\n# ------------------- Main Pipeline --------------------------\nif __name__ == \"__main__\":\n    start_time = time.time()\n    print(\"=== Starting Advanced EEG Ensemble Pipeline ===\")\n    if os.path.exists(os.path.join(INPUT_DATA_PATH, 'train.zip')):\n        print(\"Unzipping data files...\")\n        with zipfile.ZipFile(os.path.join(INPUT_DATA_PATH, 'train.zip'), 'r') as zip_ref:\n            zip_ref.extractall(WORKING_PATH)\n    print(\"\\n--- Preparing Training Data ---\")\n    train_ids = [s for s in TRAIN_SERIES if s not in VALIDATION_SPLIT_SERIES]\n    X_train, y_train, _, features_train, scaler = preprocess_data_pipeline(\n        train_ids, WORKING_PATH, is_test=False, augment=True\n    )\n    if X_train.shape[0] == 0:\n        raise ValueError(\"No training samples after preprocessing\")\n    print(f\"Train shapes: X={X_train.shape}, y={y_train.shape}, features={features_train.shape}\")\n    print(\"\\n--- Preparing Validation Data ---\")\n    X_val, y_val, _, features_val, _ = preprocess_data_pipeline(\n        VALIDATION_SPLIT_SERIES, WORKING_PATH, scaler=scaler, is_test=False\n    )\n    if X_val.shape[0] == 0:\n        raise ValueError(\"No validation samples after preprocessing\")\n    print(f\"Validation shapes: X={X_val.shape}, y={y_val.shape}, features={features_val.shape}\")\n    gc.collect()\n    print(\"\\n--- Using Cross-Validation Training Strategy ---\")\n    X_full = np.concatenate([X_train, X_val])\n    y_full = np.concatenate([y_train, y_val])\n    features_full = np.concatenate([features_train, features_val])\n    best_model_info, fold_models, history = train_with_cross_validation(\n        X_full, y_full, features=features_full, n_splits=5\n    )\n    # Ensemble predictions on validation set using TTA\n    preds_list = []\n    for model_type, model in fold_models:\n        if model_type == 'cnn_blstm' and features_val is not None:\n            val_pred = tta_predict(model, X_val, features_val)\n        else:\n            val_pred = tta_predict(model, X_val)\n        preds_list.append(val_pred)\n    blended_preds = ensemble_predictions(preds_list, y_val=y_val)\n    aucs = [roc_auc_score(y_val[:, i], blended_preds[:, i]) if len(np.unique(y_val[:, i])) > 1 else np.nan for i in range(blended_preds.shape[1])]\n    avg_auc = np.nanmean(aucs)\n    print(f\"\\n=== Ensemble Model Performance ===\")\n    \n    # Calculate and plot confusion matrices\n    cms, detailed_metrics = plot_confusion_matrices(y_val, blended_preds, TARGET_COLS)\n    print_metrics_report(detailed_metrics, TARGET_COLS)\n    \n    print(f\"\\Validaiton AUC Scores by Class:\")\n    for i, event_name in enumerate(TARGET_COLS):\n        print(f\"{event_name}: {aucs[i]:.4f}\")\n    print(f\"Average Ensemble AUC: {avg_auc:.4f}\")\n    \n    # Plot ROC curves for ensemble\n    plt.figure(figsize=(12, 10))\n    for i, event_name in enumerate(TARGET_COLS):\n        try:\n            if len(np.unique(y_val[:, i])) > 1:\n                fpr, tpr, _ = roc_curve(y_val[:, i], blended_preds[:, i])\n                plt.plot(fpr, tpr, label=f'{event_name} (AUC = {aucs[i]:.4f})')\n        except Exception as e:\n            print(f\"{event_name} ROC error: {e}\")\n    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Ensemble ROC Curves - Avg AUC: {avg_auc:.4f}')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plot_path = os.path.join(OUTPUT_PATH, f'ensemble_roc_curves.png')\n    try:\n        plt.savefig(plot_path)\n        print(f\"Ensemble ROC plot saved to: {plot_path}\")\n    except Exception as e:\n        print(f\"Error saving ensemble ROC plot: {e}\")\n    plt.close()\n    plot_history(history, model_type='ensemble')\n    print(f\"\\n=== Final Model Performance ===\")\n    print(f\"Model type: ensemble\")\n    print(f\"Validation AUC: {avg_auc:.4f}\")\n    end_time = time.time()\n    execution_time = end_time - start_time\n    hours, remainder = divmod(execution_time, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    print(f\"\\nTotal execution time: {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n    print(\"\\n=== Process Complete ===\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:07:40.464206Z","iopub.execute_input":"2025-05-02T15:07:40.464920Z","iopub.status.idle":"2025-05-02T16:12:22.674305Z","shell.execute_reply.started":"2025-05-02T15:07:40.464896Z","shell.execute_reply":"2025-05-02T16:12:22.673340Z"}},"outputs":[{"name":"stderr","text":"2025-05-02 15:07:42.692922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746198462.944313      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746198463.010362      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 2 GPU(s), memory growth enabled\nUsing mixed precision - Compute dtype: float16\n=== Starting Advanced EEG Ensemble Pipeline ===\nUnzipping data files...\n\n--- Preparing Training Data ---\nLoading training data for series [1, 2, 3, 4, 5, 6]...\nLoading series [1, 2, 3, 4, 5, 6]\nFound 72 data files\nData loaded and downsampled. Shape: (7409687, 32)\nApplying advanced filters...\nScaling data...\nCreating windows and extracting features...\nCreating windows with advanced features...\nCreating 37047 windows with size 400 and step 200\nCreated windows shape: (37047, 400, 32)\nExtracted features shape: (37047, 320)\nTrain shapes: X=(37047, 32, 400, 1), y=(37047, 6), features=(37047, 320)\n\n--- Preparing Validation Data ---\nLoading training data for series [7, 8]...\nLoading series [7, 8]\nFound 24 data files\nData loaded and downsampled. Shape: (1583211, 32)\nApplying advanced filters...\nScaling data...\nCreating windows and extracting features...\nCreating windows with advanced features...\nCreating 7915 windows with size 400 and step 200\nCreated windows shape: (7915, 400, 32)\nExtracted features shape: (7915, 320)\nValidation shapes: X=(7915, 32, 400, 1), y=(7915, 6), features=(7915, 320)\n\n--- Using Cross-Validation Training Strategy ---\n\n--- Training with 5-Fold Stratified Cross-Validation ---\n\n--- Fold 1/5 ---\nTraining eegnet_tcn model for fold 1\n\n--- Building and Training eegnet_tcn Model ---\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1746199591.225841      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1746199591.226555      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1746199615.021211     112 service.cc:148] XLA service 0x7c871804d230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1746199615.023720     112 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1746199615.023744     112 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1746199616.428862     112 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1746199630.768764     112 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_auc improved from -inf to 0.59750, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 48s - 171ms/step - accuracy: 0.1964 - auc: 0.5614 - loss: 0.4505 - val_accuracy: 0.1956 - val_auc: 0.5975 - val_loss: 0.4313 - learning_rate: 0.0010\nEpoch 2/40\n\nEpoch 2: val_auc improved from 0.59750 to 0.60997, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 21ms/step - accuracy: 0.2255 - auc: 0.5919 - loss: 0.4265 - val_accuracy: 0.2789 - val_auc: 0.6100 - val_loss: 0.4212 - learning_rate: 0.0010\nEpoch 3/40\n\nEpoch 3: val_auc improved from 0.60997 to 0.61593, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 21ms/step - accuracy: 0.2407 - auc: 0.6076 - loss: 0.4186 - val_accuracy: 0.2462 - val_auc: 0.6159 - val_loss: 0.4177 - learning_rate: 0.0010\nEpoch 4/40\n\nEpoch 4: val_auc improved from 0.61593 to 0.61669, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 21ms/step - accuracy: 0.2516 - auc: 0.6181 - loss: 0.4123 - val_accuracy: 0.2926 - val_auc: 0.6167 - val_loss: 0.4187 - learning_rate: 0.0010\nEpoch 5/40\n\nEpoch 5: val_auc did not improve from 0.61669\n282/282 - 6s - 21ms/step - accuracy: 0.2622 - auc: 0.6257 - loss: 0.4074 - val_accuracy: 0.2864 - val_auc: 0.6148 - val_loss: 0.4195 - learning_rate: 0.0010\nEpoch 6/40\n\nEpoch 6: val_auc improved from 0.61669 to 0.62620, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 21ms/step - accuracy: 0.2695 - auc: 0.6324 - loss: 0.4026 - val_accuracy: 0.2536 - val_auc: 0.6262 - val_loss: 0.4140 - learning_rate: 0.0010\nEpoch 7/40\n\nEpoch 7: val_auc improved from 0.62620 to 0.62770, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 21ms/step - accuracy: 0.2795 - auc: 0.6404 - loss: 0.3977 - val_accuracy: 0.2240 - val_auc: 0.6277 - val_loss: 0.4157 - learning_rate: 0.0010\nEpoch 8/40\n\nEpoch 8: val_auc improved from 0.62770 to 0.63054, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 21ms/step - accuracy: 0.2851 - auc: 0.6451 - loss: 0.3940 - val_accuracy: 0.2144 - val_auc: 0.6305 - val_loss: 0.4193 - learning_rate: 0.0010\nEpoch 9/40\n\nEpoch 9: val_auc improved from 0.63054 to 0.63205, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.2946 - auc: 0.6498 - loss: 0.3905 - val_accuracy: 0.2451 - val_auc: 0.6321 - val_loss: 0.4180 - learning_rate: 0.0010\nEpoch 10/40\n\nEpoch 10: val_auc improved from 0.63205 to 0.63608, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n282/282 - 6s - 22ms/step - accuracy: 0.2932 - auc: 0.6529 - loss: 0.3878 - val_accuracy: 0.2338 - val_auc: 0.6361 - val_loss: 0.4249 - learning_rate: 0.0010\nEpoch 11/40\n\nEpoch 11: val_auc did not improve from 0.63608\n282/282 - 6s - 21ms/step - accuracy: 0.3021 - auc: 0.6608 - loss: 0.3811 - val_accuracy: 0.2321 - val_auc: 0.6341 - val_loss: 0.4355 - learning_rate: 5.0000e-04\nEpoch 12/40\n\nEpoch 12: val_auc improved from 0.63608 to 0.63682, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.3034 - auc: 0.6638 - loss: 0.3783 - val_accuracy: 0.2503 - val_auc: 0.6368 - val_loss: 0.4328 - learning_rate: 5.0000e-04\nEpoch 13/40\n\nEpoch 13: val_auc did not improve from 0.63682\n282/282 - 6s - 21ms/step - accuracy: 0.3090 - auc: 0.6671 - loss: 0.3761 - val_accuracy: 0.2542 - val_auc: 0.6364 - val_loss: 0.4363 - learning_rate: 5.0000e-04\nEpoch 14/40\n\nEpoch 14: val_auc did not improve from 0.63682\n\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n282/282 - 6s - 21ms/step - accuracy: 0.3117 - auc: 0.6693 - loss: 0.3739 - val_accuracy: 0.2469 - val_auc: 0.6356 - val_loss: 0.4376 - learning_rate: 5.0000e-04\nEpoch 15/40\n\nEpoch 15: val_auc did not improve from 0.63682\n282/282 - 6s - 21ms/step - accuracy: 0.3171 - auc: 0.6733 - loss: 0.3705 - val_accuracy: 0.2529 - val_auc: 0.6363 - val_loss: 0.4401 - learning_rate: 2.5000e-04\nEpoch 16/40\n\nEpoch 16: val_auc did not improve from 0.63682\n282/282 - 6s - 21ms/step - accuracy: 0.3185 - auc: 0.6760 - loss: 0.3681 - val_accuracy: 0.2519 - val_auc: 0.6353 - val_loss: 0.4487 - learning_rate: 2.5000e-04\nEpoch 17/40\n\nEpoch 17: val_auc did not improve from 0.63682\n282/282 - 6s - 21ms/step - accuracy: 0.3159 - auc: 0.6765 - loss: 0.3672 - val_accuracy: 0.2476 - val_auc: 0.6349 - val_loss: 0.4532 - learning_rate: 2.5000e-04\nEpoch 18/40\n\nEpoch 18: val_auc did not improve from 0.63682\n\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n282/282 - 6s - 21ms/step - accuracy: 0.3183 - auc: 0.6783 - loss: 0.3649 - val_accuracy: 0.2500 - val_auc: 0.6348 - val_loss: 0.4520 - learning_rate: 2.5000e-04\nEpoch 19/40\n\nEpoch 19: val_auc did not improve from 0.63682\n282/282 - 6s - 21ms/step - accuracy: 0.3221 - auc: 0.6831 - loss: 0.3621 - val_accuracy: 0.2499 - val_auc: 0.6347 - val_loss: 0.4539 - learning_rate: 1.2500e-04\nEpoch 20/40\n\nEpoch 20: val_auc did not improve from 0.63682\n282/282 - 6s - 22ms/step - accuracy: 0.3225 - auc: 0.6830 - loss: 0.3613 - val_accuracy: 0.2452 - val_auc: 0.6348 - val_loss: 0.4591 - learning_rate: 1.2500e-04\nEpoch 21/40\n\nEpoch 21: val_auc did not improve from 0.63682\n282/282 - 6s - 22ms/step - accuracy: 0.3277 - auc: 0.6844 - loss: 0.3607 - val_accuracy: 0.2505 - val_auc: 0.6349 - val_loss: 0.4594 - learning_rate: 1.2500e-04\nEpoch 22/40\n\nEpoch 22: val_auc did not improve from 0.63682\n\nEpoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n282/282 - 6s - 21ms/step - accuracy: 0.3253 - auc: 0.6841 - loss: 0.3594 - val_accuracy: 0.2481 - val_auc: 0.6345 - val_loss: 0.4619 - learning_rate: 1.2500e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 1 eegnet_tcn - Validation AUC: 0.7271\n\n--- Fold 2/5 ---\nTraining cnn_blstm model for fold 2\n\n--- Building and Training cnn_blstm Model ---\nEpoch 1/40\n\nEpoch 1: val_auc improved from -inf to 0.57822, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 41s - 146ms/step - accuracy: 0.1798 - auc: 0.5568 - loss: 0.4516 - val_accuracy: 0.1427 - val_auc: 0.5782 - val_loss: 0.4330 - learning_rate: 0.0010\nEpoch 2/40\n\nEpoch 2: val_auc improved from 0.57822 to 0.60281, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 22s - 80ms/step - accuracy: 0.2172 - auc: 0.5947 - loss: 0.4252 - val_accuracy: 0.2017 - val_auc: 0.6028 - val_loss: 0.4238 - learning_rate: 0.0010\nEpoch 3/40\n\nEpoch 3: val_auc improved from 0.60281 to 0.60683, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 80ms/step - accuracy: 0.2441 - auc: 0.6099 - loss: 0.4181 - val_accuracy: 0.2241 - val_auc: 0.6068 - val_loss: 0.4220 - learning_rate: 0.0010\nEpoch 4/40\n\nEpoch 4: val_auc improved from 0.60683 to 0.60884, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.2602 - auc: 0.6200 - loss: 0.4118 - val_accuracy: 0.2375 - val_auc: 0.6088 - val_loss: 0.4225 - learning_rate: 0.0010\nEpoch 5/40\n\nEpoch 5: val_auc did not improve from 0.60884\n282/282 - 22s - 79ms/step - accuracy: 0.2671 - auc: 0.6305 - loss: 0.4055 - val_accuracy: 0.2612 - val_auc: 0.6088 - val_loss: 0.4286 - learning_rate: 0.0010\nEpoch 6/40\n\nEpoch 6: val_auc did not improve from 0.60884\n282/282 - 23s - 80ms/step - accuracy: 0.2751 - auc: 0.6394 - loss: 0.3995 - val_accuracy: 0.1791 - val_auc: 0.6086 - val_loss: 0.4255 - learning_rate: 0.0010\nEpoch 7/40\n\nEpoch 7: val_auc improved from 0.60884 to 0.61180, saving model to /kaggle/working/best_cnn_blstm_model.keras\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n282/282 - 23s - 82ms/step - accuracy: 0.2789 - auc: 0.6458 - loss: 0.3941 - val_accuracy: 0.2711 - val_auc: 0.6118 - val_loss: 0.4261 - learning_rate: 0.0010\nEpoch 8/40\n\nEpoch 8: val_auc did not improve from 0.61180\n282/282 - 23s - 80ms/step - accuracy: 0.2862 - auc: 0.6621 - loss: 0.3817 - val_accuracy: 0.2744 - val_auc: 0.6115 - val_loss: 0.4341 - learning_rate: 5.0000e-04\nEpoch 9/40\n\nEpoch 9: val_auc improved from 0.61180 to 0.61271, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 80ms/step - accuracy: 0.2908 - auc: 0.6694 - loss: 0.3745 - val_accuracy: 0.2787 - val_auc: 0.6127 - val_loss: 0.4401 - learning_rate: 5.0000e-04\nEpoch 10/40\n\nEpoch 10: val_auc did not improve from 0.61271\n282/282 - 23s - 80ms/step - accuracy: 0.2983 - auc: 0.6783 - loss: 0.3664 - val_accuracy: 0.2648 - val_auc: 0.6115 - val_loss: 0.4490 - learning_rate: 5.0000e-04\nEpoch 11/40\n\nEpoch 11: val_auc did not improve from 0.61271\n\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n282/282 - 23s - 80ms/step - accuracy: 0.2998 - auc: 0.6844 - loss: 0.3603 - val_accuracy: 0.2791 - val_auc: 0.6094 - val_loss: 0.4568 - learning_rate: 5.0000e-04\nEpoch 12/40\n\nEpoch 12: val_auc improved from 0.61271 to 0.61432, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.3051 - auc: 0.6905 - loss: 0.3540 - val_accuracy: 0.2638 - val_auc: 0.6143 - val_loss: 0.4402 - learning_rate: 2.5000e-04\nEpoch 13/40\n\nEpoch 13: val_auc did not improve from 0.61432\n282/282 - 23s - 81ms/step - accuracy: 0.3090 - auc: 0.6953 - loss: 0.3495 - val_accuracy: 0.2550 - val_auc: 0.6131 - val_loss: 0.4428 - learning_rate: 2.5000e-04\nEpoch 14/40\n\nEpoch 14: val_auc did not improve from 0.61432\n282/282 - 22s - 79ms/step - accuracy: 0.3154 - auc: 0.6995 - loss: 0.3447 - val_accuracy: 0.2722 - val_auc: 0.6140 - val_loss: 0.4488 - learning_rate: 2.5000e-04\nEpoch 15/40\n\nEpoch 15: val_auc did not improve from 0.61432\n\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n282/282 - 22s - 80ms/step - accuracy: 0.3161 - auc: 0.7028 - loss: 0.3406 - val_accuracy: 0.2856 - val_auc: 0.6139 - val_loss: 0.4521 - learning_rate: 2.5000e-04\nEpoch 16/40\n\nEpoch 16: val_auc improved from 0.61432 to 0.61572, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.3223 - auc: 0.7058 - loss: 0.3362 - val_accuracy: 0.2712 - val_auc: 0.6157 - val_loss: 0.4514 - learning_rate: 1.2500e-04\nEpoch 17/40\n\nEpoch 17: val_auc did not improve from 0.61572\n282/282 - 23s - 81ms/step - accuracy: 0.3231 - auc: 0.7093 - loss: 0.3326 - val_accuracy: 0.2826 - val_auc: 0.6153 - val_loss: 0.4520 - learning_rate: 1.2500e-04\nEpoch 18/40\n\nEpoch 18: val_auc did not improve from 0.61572\n282/282 - 23s - 81ms/step - accuracy: 0.3235 - auc: 0.7128 - loss: 0.3291 - val_accuracy: 0.2803 - val_auc: 0.6156 - val_loss: 0.4581 - learning_rate: 1.2500e-04\nEpoch 19/40\n\nEpoch 19: val_auc did not improve from 0.61572\n\nEpoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n282/282 - 22s - 80ms/step - accuracy: 0.3298 - auc: 0.7145 - loss: 0.3264 - val_accuracy: 0.2834 - val_auc: 0.6151 - val_loss: 0.4590 - learning_rate: 1.2500e-04\nEpoch 20/40\n\nEpoch 20: val_auc did not improve from 0.61572\n282/282 - 23s - 80ms/step - accuracy: 0.3302 - auc: 0.7161 - loss: 0.3244 - val_accuracy: 0.2781 - val_auc: 0.6144 - val_loss: 0.4587 - learning_rate: 6.2500e-05\nEpoch 21/40\n\nEpoch 21: val_auc did not improve from 0.61572\n282/282 - 23s - 80ms/step - accuracy: 0.3318 - auc: 0.7178 - loss: 0.3217 - val_accuracy: 0.2839 - val_auc: 0.6143 - val_loss: 0.4622 - learning_rate: 6.2500e-05\nEpoch 22/40\n\nEpoch 22: val_auc did not improve from 0.61572\n282/282 - 22s - 80ms/step - accuracy: 0.3327 - auc: 0.7192 - loss: 0.3199 - val_accuracy: 0.2784 - val_auc: 0.6134 - val_loss: 0.4652 - learning_rate: 6.2500e-05\nEpoch 23/40\n\nEpoch 23: val_auc did not improve from 0.61572\n\nEpoch 23: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n282/282 - 23s - 80ms/step - accuracy: 0.3315 - auc: 0.7201 - loss: 0.3184 - val_accuracy: 0.2857 - val_auc: 0.6130 - val_loss: 0.4656 - learning_rate: 6.2500e-05\nEpoch 24/40\n\nEpoch 24: val_auc did not improve from 0.61572\n282/282 - 23s - 81ms/step - accuracy: 0.3390 - auc: 0.7226 - loss: 0.3164 - val_accuracy: 0.2843 - val_auc: 0.6116 - val_loss: 0.4671 - learning_rate: 3.1250e-05\nEpoch 25/40\n\nEpoch 25: val_auc did not improve from 0.61572\n282/282 - 22s - 79ms/step - accuracy: 0.3335 - auc: 0.7209 - loss: 0.3155 - val_accuracy: 0.2834 - val_auc: 0.6116 - val_loss: 0.4683 - learning_rate: 3.1250e-05\nEpoch 26/40\n\nEpoch 26: val_auc did not improve from 0.61572\n282/282 - 22s - 80ms/step - accuracy: 0.3330 - auc: 0.7236 - loss: 0.3149 - val_accuracy: 0.2828 - val_auc: 0.6125 - val_loss: 0.4689 - learning_rate: 3.1250e-05\nEpoch 26: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 2 cnn_blstm - Validation AUC: 0.6974\n\n--- Fold 3/5 ---\nTraining attention model for fold 3\n\n--- Building and Training attention Model ---\nEpoch 1/40\n\nEpoch 1: val_auc improved from -inf to 0.54337, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 48s - 172ms/step - accuracy: 0.1731 - auc: 0.5162 - loss: 0.6052 - val_accuracy: 0.0831 - val_auc: 0.5434 - val_loss: 0.4435 - learning_rate: 0.0010\nEpoch 2/40\n\nEpoch 2: val_auc improved from 0.54337 to 0.55829, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 77ms/step - accuracy: 0.1679 - auc: 0.5355 - loss: 0.4695 - val_accuracy: 0.0648 - val_auc: 0.5583 - val_loss: 0.4349 - learning_rate: 0.0010\nEpoch 3/40\n\nEpoch 3: val_auc improved from 0.55829 to 0.57074, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.1590 - auc: 0.5540 - loss: 0.4437 - val_accuracy: 0.0567 - val_auc: 0.5707 - val_loss: 0.4297 - learning_rate: 0.0010\nEpoch 4/40\n\nEpoch 4: val_auc improved from 0.57074 to 0.59243, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 77ms/step - accuracy: 0.1582 - auc: 0.5666 - loss: 0.4362 - val_accuracy: 0.0603 - val_auc: 0.5924 - val_loss: 0.4236 - learning_rate: 0.0010\nEpoch 5/40\n\nEpoch 5: val_auc improved from 0.59243 to 0.59448, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 76ms/step - accuracy: 0.1566 - auc: 0.5723 - loss: 0.4314 - val_accuracy: 0.0484 - val_auc: 0.5945 - val_loss: 0.4270 - learning_rate: 0.0010\nEpoch 6/40\n\nEpoch 6: val_auc did not improve from 0.59448\n282/282 - 16s - 56ms/step - accuracy: 0.1573 - auc: 0.5772 - loss: 0.4297 - val_accuracy: 0.0532 - val_auc: 0.5791 - val_loss: 0.4285 - learning_rate: 0.0010\nEpoch 7/40\n\nEpoch 7: val_auc improved from 0.59448 to 0.60159, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.1743 - auc: 0.5779 - loss: 0.4287 - val_accuracy: 0.0906 - val_auc: 0.6016 - val_loss: 0.4180 - learning_rate: 0.0010\nEpoch 8/40\n\nEpoch 8: val_auc did not improve from 0.60159\n282/282 - 16s - 56ms/step - accuracy: 0.1709 - auc: 0.5840 - loss: 0.4255 - val_accuracy: 0.0607 - val_auc: 0.6014 - val_loss: 0.4225 - learning_rate: 0.0010\nEpoch 9/40\n\nEpoch 9: val_auc improved from 0.60159 to 0.60637, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 79ms/step - accuracy: 0.1750 - auc: 0.5892 - loss: 0.4245 - val_accuracy: 0.1752 - val_auc: 0.6064 - val_loss: 0.4171 - learning_rate: 0.0010\nEpoch 10/40\n\nEpoch 10: val_auc did not improve from 0.60637\n282/282 - 15s - 55ms/step - accuracy: 0.1934 - auc: 0.5943 - loss: 0.4219 - val_accuracy: 0.0701 - val_auc: 0.6060 - val_loss: 0.4188 - learning_rate: 0.0010\nEpoch 11/40\n\nEpoch 11: val_auc did not improve from 0.60637\n282/282 - 16s - 56ms/step - accuracy: 0.1855 - auc: 0.5895 - loss: 0.4236 - val_accuracy: 0.3161 - val_auc: 0.5838 - val_loss: 0.4207 - learning_rate: 0.0010\nEpoch 12/40\n\nEpoch 12: val_auc improved from 0.60637 to 0.61381, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.2159 - auc: 0.5972 - loss: 0.4195 - val_accuracy: 0.1371 - val_auc: 0.6138 - val_loss: 0.4082 - learning_rate: 0.0010\nEpoch 13/40\n\nEpoch 13: val_auc improved from 0.61381 to 0.61873, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.1926 - auc: 0.5856 - loss: 0.4237 - val_accuracy: 0.0479 - val_auc: 0.6187 - val_loss: 0.4066 - learning_rate: 0.0010\nEpoch 14/40\n\nEpoch 14: val_auc improved from 0.61873 to 0.63149, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.2110 - auc: 0.6000 - loss: 0.4142 - val_accuracy: 0.1924 - val_auc: 0.6315 - val_loss: 0.3969 - learning_rate: 0.0010\nEpoch 15/40\n\nEpoch 15: val_auc did not improve from 0.63149\n282/282 - 16s - 56ms/step - accuracy: 0.2336 - auc: 0.6084 - loss: 0.4102 - val_accuracy: 0.2801 - val_auc: 0.6115 - val_loss: 0.4049 - learning_rate: 0.0010\nEpoch 16/40\n\nEpoch 16: val_auc improved from 0.63149 to 0.64236, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 79ms/step - accuracy: 0.2613 - auc: 0.6095 - loss: 0.4084 - val_accuracy: 0.1808 - val_auc: 0.6424 - val_loss: 0.3918 - learning_rate: 0.0010\nEpoch 17/40\n\nEpoch 17: val_auc did not improve from 0.64236\n282/282 - 15s - 54ms/step - accuracy: 0.2427 - auc: 0.6125 - loss: 0.4091 - val_accuracy: 0.1561 - val_auc: 0.6306 - val_loss: 0.3984 - learning_rate: 0.0010\nEpoch 18/40\n\nEpoch 18: val_auc did not improve from 0.64236\n282/282 - 15s - 55ms/step - accuracy: 0.2453 - auc: 0.5989 - loss: 0.4152 - val_accuracy: 0.1321 - val_auc: 0.6268 - val_loss: 0.3984 - learning_rate: 0.0010\nEpoch 19/40\n\nEpoch 19: val_auc did not improve from 0.64236\n282/282 - 16s - 55ms/step - accuracy: 0.2523 - auc: 0.6089 - loss: 0.4098 - val_accuracy: 0.1584 - val_auc: 0.6213 - val_loss: 0.4013 - learning_rate: 0.0010\nEpoch 20/40\n\nEpoch 20: val_auc did not improve from 0.64236\n\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n282/282 - 16s - 55ms/step - accuracy: 0.2548 - auc: 0.6097 - loss: 0.4096 - val_accuracy: 0.1135 - val_auc: 0.6258 - val_loss: 0.4002 - learning_rate: 0.0010\nEpoch 21/40\n\nEpoch 21: val_auc did not improve from 0.64236\n282/282 - 15s - 55ms/step - accuracy: 0.2670 - auc: 0.6242 - loss: 0.3965 - val_accuracy: 0.1191 - val_auc: 0.6383 - val_loss: 0.3898 - learning_rate: 5.0000e-04\nEpoch 22/40\n\nEpoch 22: val_auc improved from 0.64236 to 0.65111, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.2813 - auc: 0.6295 - loss: 0.3904 - val_accuracy: 0.2273 - val_auc: 0.6511 - val_loss: 0.3861 - learning_rate: 5.0000e-04\nEpoch 23/40\n\nEpoch 23: val_auc improved from 0.65111 to 0.65301, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.2706 - auc: 0.6385 - loss: 0.3861 - val_accuracy: 0.2599 - val_auc: 0.6530 - val_loss: 0.3830 - learning_rate: 5.0000e-04\nEpoch 24/40\n\nEpoch 24: val_auc did not improve from 0.65301\n282/282 - 16s - 55ms/step - accuracy: 0.2763 - auc: 0.6433 - loss: 0.3808 - val_accuracy: 0.1174 - val_auc: 0.6486 - val_loss: 0.3877 - learning_rate: 5.0000e-04\nEpoch 25/40\n\nEpoch 25: val_auc did not improve from 0.65301\n282/282 - 16s - 57ms/step - accuracy: 0.2863 - auc: 0.6478 - loss: 0.3791 - val_accuracy: 0.0932 - val_auc: 0.6483 - val_loss: 0.3873 - learning_rate: 5.0000e-04\nEpoch 26/40\n\nEpoch 26: val_auc did not improve from 0.65301\n282/282 - 16s - 55ms/step - accuracy: 0.2758 - auc: 0.6520 - loss: 0.3741 - val_accuracy: 0.1745 - val_auc: 0.6450 - val_loss: 0.3887 - learning_rate: 5.0000e-04\nEpoch 27/40\n\nEpoch 27: val_auc improved from 0.65301 to 0.65329, saving model to /kaggle/working/best_attention_model.keras\n\nEpoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n282/282 - 22s - 77ms/step - accuracy: 0.2917 - auc: 0.6556 - loss: 0.3718 - val_accuracy: 0.1573 - val_auc: 0.6533 - val_loss: 0.3982 - learning_rate: 5.0000e-04\nEpoch 28/40\n\nEpoch 28: val_auc improved from 0.65329 to 0.65520, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.3017 - auc: 0.6628 - loss: 0.3623 - val_accuracy: 0.3194 - val_auc: 0.6552 - val_loss: 0.3887 - learning_rate: 2.5000e-04\nEpoch 29/40\n\nEpoch 29: val_auc did not improve from 0.65520\n282/282 - 16s - 56ms/step - accuracy: 0.2957 - auc: 0.6713 - loss: 0.3550 - val_accuracy: 0.3104 - val_auc: 0.6529 - val_loss: 0.3910 - learning_rate: 2.5000e-04\nEpoch 30/40\n\nEpoch 30: val_auc did not improve from 0.65520\n282/282 - 16s - 57ms/step - accuracy: 0.3064 - auc: 0.6768 - loss: 0.3499 - val_accuracy: 0.3257 - val_auc: 0.6537 - val_loss: 0.3965 - learning_rate: 2.5000e-04\nEpoch 31/40\n\nEpoch 31: val_auc did not improve from 0.65520\n\nEpoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n282/282 - 16s - 55ms/step - accuracy: 0.3286 - auc: 0.6815 - loss: 0.3451 - val_accuracy: 0.2976 - val_auc: 0.6545 - val_loss: 0.3975 - learning_rate: 2.5000e-04\nEpoch 32/40\n\nEpoch 32: val_auc did not improve from 0.65520\n282/282 - 15s - 55ms/step - accuracy: 0.3237 - auc: 0.6854 - loss: 0.3387 - val_accuracy: 0.3186 - val_auc: 0.6552 - val_loss: 0.4035 - learning_rate: 1.2500e-04\nEpoch 33/40\n\nEpoch 33: val_auc improved from 0.65520 to 0.65547, saving model to /kaggle/working/best_attention_model.keras\n282/282 - 22s - 78ms/step - accuracy: 0.3119 - auc: 0.6918 - loss: 0.3334 - val_accuracy: 0.3245 - val_auc: 0.6555 - val_loss: 0.4103 - learning_rate: 1.2500e-04\nEpoch 34/40\n\nEpoch 34: val_auc did not improve from 0.65547\n282/282 - 16s - 55ms/step - accuracy: 0.3090 - auc: 0.6920 - loss: 0.3302 - val_accuracy: 0.3272 - val_auc: 0.6538 - val_loss: 0.4112 - learning_rate: 1.2500e-04\nEpoch 35/40\n\nEpoch 35: val_auc did not improve from 0.65547\n\nEpoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n282/282 - 16s - 56ms/step - accuracy: 0.3299 - auc: 0.6965 - loss: 0.3257 - val_accuracy: 0.3175 - val_auc: 0.6509 - val_loss: 0.4196 - learning_rate: 1.2500e-04\nEpoch 36/40\n\nEpoch 36: val_auc did not improve from 0.65547\n282/282 - 16s - 55ms/step - accuracy: 0.3201 - auc: 0.7016 - loss: 0.3202 - val_accuracy: 0.3535 - val_auc: 0.6517 - val_loss: 0.4294 - learning_rate: 6.2500e-05\nEpoch 37/40\n\nEpoch 37: val_auc did not improve from 0.65547\n282/282 - 16s - 55ms/step - accuracy: 0.3303 - auc: 0.7030 - loss: 0.3171 - val_accuracy: 0.3425 - val_auc: 0.6507 - val_loss: 0.4331 - learning_rate: 6.2500e-05\nEpoch 38/40\n\nEpoch 38: val_auc did not improve from 0.65547\n282/282 - 15s - 55ms/step - accuracy: 0.3175 - auc: 0.7053 - loss: 0.3157 - val_accuracy: 0.3359 - val_auc: 0.6512 - val_loss: 0.4434 - learning_rate: 6.2500e-05\nEpoch 39/40\n\nEpoch 39: val_auc did not improve from 0.65547\n\nEpoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n282/282 - 16s - 55ms/step - accuracy: 0.3220 - auc: 0.7060 - loss: 0.3128 - val_accuracy: 0.3346 - val_auc: 0.6496 - val_loss: 0.4528 - learning_rate: 6.2500e-05\nEpoch 40/40\n\nEpoch 40: val_auc did not improve from 0.65547\n282/282 - 16s - 55ms/step - accuracy: 0.3229 - auc: 0.7097 - loss: 0.3106 - val_accuracy: 0.3403 - val_auc: 0.6501 - val_loss: 0.4534 - learning_rate: 3.1250e-05\nRestoring model weights from the end of the best epoch: 33.\nFold 3 attention - Validation AUC: 0.7611\n\n--- Fold 4/5 ---\nTraining eegnet_tcn model for fold 4\n\n--- Building and Training eegnet_tcn Model ---\nEpoch 1/40\n\nEpoch 1: val_auc improved from -inf to 0.59488, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 43s - 151ms/step - accuracy: 0.1869 - auc: 0.5606 - loss: 0.4508 - val_accuracy: 0.1600 - val_auc: 0.5949 - val_loss: 0.4304 - learning_rate: 0.0010\nEpoch 2/40\n\nEpoch 2: val_auc improved from 0.59488 to 0.60385, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.2125 - auc: 0.5883 - loss: 0.4289 - val_accuracy: 0.2553 - val_auc: 0.6039 - val_loss: 0.4216 - learning_rate: 0.0010\nEpoch 3/40\n\nEpoch 3: val_auc improved from 0.60385 to 0.61367, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.2321 - auc: 0.6039 - loss: 0.4216 - val_accuracy: 0.2806 - val_auc: 0.6137 - val_loss: 0.4180 - learning_rate: 0.0010\nEpoch 4/40\n\nEpoch 4: val_auc improved from 0.61367 to 0.61565, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.2436 - auc: 0.6153 - loss: 0.4154 - val_accuracy: 0.2885 - val_auc: 0.6157 - val_loss: 0.4204 - learning_rate: 0.0010\nEpoch 5/40\n\nEpoch 5: val_auc did not improve from 0.61565\n282/282 - 6s - 21ms/step - accuracy: 0.2569 - auc: 0.6239 - loss: 0.4100 - val_accuracy: 0.2814 - val_auc: 0.6097 - val_loss: 0.4253 - learning_rate: 0.0010\nEpoch 6/40\n\nEpoch 6: val_auc improved from 0.61565 to 0.62102, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.2604 - auc: 0.6295 - loss: 0.4061 - val_accuracy: 0.2526 - val_auc: 0.6210 - val_loss: 0.4277 - learning_rate: 0.0010\nEpoch 7/40\n\nEpoch 7: val_auc improved from 0.62102 to 0.62231, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n282/282 - 6s - 22ms/step - accuracy: 0.2733 - auc: 0.6368 - loss: 0.4012 - val_accuracy: 0.2615 - val_auc: 0.6223 - val_loss: 0.4333 - learning_rate: 0.0010\nEpoch 8/40\n\nEpoch 8: val_auc improved from 0.62231 to 0.62392, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.2910 - auc: 0.6457 - loss: 0.3938 - val_accuracy: 0.2817 - val_auc: 0.6239 - val_loss: 0.4432 - learning_rate: 5.0000e-04\nEpoch 9/40\n\nEpoch 9: val_auc improved from 0.62392 to 0.62549, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 23ms/step - accuracy: 0.2948 - auc: 0.6514 - loss: 0.3900 - val_accuracy: 0.2744 - val_auc: 0.6255 - val_loss: 0.4569 - learning_rate: 5.0000e-04\nEpoch 10/40\n\nEpoch 10: val_auc improved from 0.62549 to 0.62560, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 23ms/step - accuracy: 0.2950 - auc: 0.6535 - loss: 0.3881 - val_accuracy: 0.2701 - val_auc: 0.6256 - val_loss: 0.4673 - learning_rate: 5.0000e-04\nEpoch 11/40\n\nEpoch 11: val_auc improved from 0.62560 to 0.62711, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n282/282 - 6s - 22ms/step - accuracy: 0.2972 - auc: 0.6571 - loss: 0.3847 - val_accuracy: 0.2673 - val_auc: 0.6271 - val_loss: 0.4714 - learning_rate: 5.0000e-04\nEpoch 12/40\n\nEpoch 12: val_auc improved from 0.62711 to 0.62819, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.3003 - auc: 0.6618 - loss: 0.3806 - val_accuracy: 0.2609 - val_auc: 0.6282 - val_loss: 0.4709 - learning_rate: 2.5000e-04\nEpoch 13/40\n\nEpoch 13: val_auc improved from 0.62819 to 0.62904, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.3079 - auc: 0.6643 - loss: 0.3781 - val_accuracy: 0.2509 - val_auc: 0.6290 - val_loss: 0.4804 - learning_rate: 2.5000e-04\nEpoch 14/40\n\nEpoch 14: val_auc did not improve from 0.62904\n282/282 - 6s - 21ms/step - accuracy: 0.3111 - auc: 0.6668 - loss: 0.3760 - val_accuracy: 0.2447 - val_auc: 0.6270 - val_loss: 0.4918 - learning_rate: 2.5000e-04\nEpoch 15/40\n\nEpoch 15: val_auc did not improve from 0.62904\n\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n282/282 - 6s - 22ms/step - accuracy: 0.3086 - auc: 0.6689 - loss: 0.3751 - val_accuracy: 0.2500 - val_auc: 0.6279 - val_loss: 0.4920 - learning_rate: 2.5000e-04\nEpoch 16/40\n\nEpoch 16: val_auc improved from 0.62904 to 0.63069, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.3145 - auc: 0.6711 - loss: 0.3727 - val_accuracy: 0.2609 - val_auc: 0.6307 - val_loss: 0.4778 - learning_rate: 1.2500e-04\nEpoch 17/40\n\nEpoch 17: val_auc did not improve from 0.63069\n282/282 - 6s - 22ms/step - accuracy: 0.3165 - auc: 0.6734 - loss: 0.3711 - val_accuracy: 0.2571 - val_auc: 0.6303 - val_loss: 0.4805 - learning_rate: 1.2500e-04\nEpoch 18/40\n\nEpoch 18: val_auc did not improve from 0.63069\n282/282 - 6s - 22ms/step - accuracy: 0.3173 - auc: 0.6737 - loss: 0.3700 - val_accuracy: 0.2514 - val_auc: 0.6296 - val_loss: 0.4887 - learning_rate: 1.2500e-04\nEpoch 19/40\n\nEpoch 19: val_auc did not improve from 0.63069\n\nEpoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n282/282 - 6s - 22ms/step - accuracy: 0.3171 - auc: 0.6739 - loss: 0.3690 - val_accuracy: 0.2497 - val_auc: 0.6292 - val_loss: 0.4890 - learning_rate: 1.2500e-04\nEpoch 20/40\n\nEpoch 20: val_auc improved from 0.63069 to 0.63114, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.3168 - auc: 0.6768 - loss: 0.3674 - val_accuracy: 0.2524 - val_auc: 0.6311 - val_loss: 0.4882 - learning_rate: 6.2500e-05\nEpoch 21/40\n\nEpoch 21: val_auc improved from 0.63114 to 0.63127, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.3177 - auc: 0.6765 - loss: 0.3672 - val_accuracy: 0.2536 - val_auc: 0.6313 - val_loss: 0.4905 - learning_rate: 6.2500e-05\nEpoch 22/40\n\nEpoch 22: val_auc did not improve from 0.63127\n282/282 - 6s - 21ms/step - accuracy: 0.3181 - auc: 0.6760 - loss: 0.3671 - val_accuracy: 0.2493 - val_auc: 0.6313 - val_loss: 0.4918 - learning_rate: 6.2500e-05\nEpoch 23/40\n\nEpoch 23: val_auc did not improve from 0.63127\n\nEpoch 23: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n282/282 - 6s - 22ms/step - accuracy: 0.3196 - auc: 0.6775 - loss: 0.3665 - val_accuracy: 0.2540 - val_auc: 0.6308 - val_loss: 0.4945 - learning_rate: 6.2500e-05\nEpoch 24/40\n\nEpoch 24: val_auc did not improve from 0.63127\n282/282 - 6s - 22ms/step - accuracy: 0.3248 - auc: 0.6777 - loss: 0.3655 - val_accuracy: 0.2461 - val_auc: 0.6312 - val_loss: 0.5010 - learning_rate: 3.1250e-05\nEpoch 25/40\n\nEpoch 25: val_auc improved from 0.63127 to 0.63149, saving model to /kaggle/working/best_eegnet_tcn_model.keras\n282/282 - 6s - 22ms/step - accuracy: 0.3196 - auc: 0.6780 - loss: 0.3652 - val_accuracy: 0.2464 - val_auc: 0.6315 - val_loss: 0.5027 - learning_rate: 3.1250e-05\nEpoch 26/40\n\nEpoch 26: val_auc did not improve from 0.63149\n282/282 - 6s - 21ms/step - accuracy: 0.3224 - auc: 0.6792 - loss: 0.3646 - val_accuracy: 0.2466 - val_auc: 0.6312 - val_loss: 0.5019 - learning_rate: 3.1250e-05\nEpoch 27/40\n\nEpoch 27: val_auc did not improve from 0.63149\n\nEpoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n282/282 - 6s - 21ms/step - accuracy: 0.3219 - auc: 0.6789 - loss: 0.3650 - val_accuracy: 0.2450 - val_auc: 0.6308 - val_loss: 0.5032 - learning_rate: 3.1250e-05\nEpoch 28/40\n\nEpoch 28: val_auc did not improve from 0.63149\n282/282 - 6s - 22ms/step - accuracy: 0.3205 - auc: 0.6783 - loss: 0.3643 - val_accuracy: 0.2439 - val_auc: 0.6309 - val_loss: 0.5068 - learning_rate: 1.5625e-05\nEpoch 29/40\n\nEpoch 29: val_auc did not improve from 0.63149\n282/282 - 6s - 22ms/step - accuracy: 0.3214 - auc: 0.6809 - loss: 0.3631 - val_accuracy: 0.2438 - val_auc: 0.6312 - val_loss: 0.5071 - learning_rate: 1.5625e-05\nEpoch 30/40\n\nEpoch 30: val_auc did not improve from 0.63149\n282/282 - 6s - 22ms/step - accuracy: 0.3219 - auc: 0.6806 - loss: 0.3640 - val_accuracy: 0.2434 - val_auc: 0.6311 - val_loss: 0.5064 - learning_rate: 1.5625e-05\nEpoch 31/40\n\nEpoch 31: val_auc did not improve from 0.63149\n\nEpoch 31: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n282/282 - 6s - 22ms/step - accuracy: 0.3234 - auc: 0.6808 - loss: 0.3622 - val_accuracy: 0.2439 - val_auc: 0.6313 - val_loss: 0.5082 - learning_rate: 1.5625e-05\nEpoch 32/40\n\nEpoch 32: val_auc did not improve from 0.63149\n282/282 - 6s - 22ms/step - accuracy: 0.3238 - auc: 0.6803 - loss: 0.3632 - val_accuracy: 0.2424 - val_auc: 0.6307 - val_loss: 0.5103 - learning_rate: 7.8125e-06\nEpoch 33/40\n\nEpoch 33: val_auc did not improve from 0.63149\n282/282 - 6s - 22ms/step - accuracy: 0.3257 - auc: 0.6810 - loss: 0.3627 - val_accuracy: 0.2413 - val_auc: 0.6309 - val_loss: 0.5106 - learning_rate: 7.8125e-06\nEpoch 34/40\n\nEpoch 34: val_auc did not improve from 0.63149\n282/282 - 6s - 22ms/step - accuracy: 0.3255 - auc: 0.6808 - loss: 0.3627 - val_accuracy: 0.2419 - val_auc: 0.6310 - val_loss: 0.5108 - learning_rate: 7.8125e-06\nEpoch 35/40\n\nEpoch 35: val_auc did not improve from 0.63149\n\nEpoch 35: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n282/282 - 6s - 22ms/step - accuracy: 0.3219 - auc: 0.6804 - loss: 0.3631 - val_accuracy: 0.2409 - val_auc: 0.6309 - val_loss: 0.5106 - learning_rate: 7.8125e-06\nEpoch 35: early stopping\nRestoring model weights from the end of the best epoch: 25.\nFold 4 eegnet_tcn - Validation AUC: 0.7361\n\n--- Fold 5/5 ---\nTraining cnn_blstm model for fold 5\n\n--- Building and Training cnn_blstm Model ---\nEpoch 1/40\n\nEpoch 1: val_auc improved from -inf to 0.57940, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 36s - 129ms/step - accuracy: 0.1817 - auc: 0.5579 - loss: 0.4534 - val_accuracy: 0.0960 - val_auc: 0.5794 - val_loss: 0.4310 - learning_rate: 0.0010\nEpoch 2/40\n\nEpoch 2: val_auc improved from 0.57940 to 0.60308, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.2101 - auc: 0.5910 - loss: 0.4272 - val_accuracy: 0.1671 - val_auc: 0.6031 - val_loss: 0.4203 - learning_rate: 0.0010\nEpoch 3/40\n\nEpoch 3: val_auc improved from 0.60308 to 0.61034, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.2351 - auc: 0.6040 - loss: 0.4206 - val_accuracy: 0.1649 - val_auc: 0.6103 - val_loss: 0.4175 - learning_rate: 0.0010\nEpoch 4/40\n\nEpoch 4: val_auc improved from 0.61034 to 0.61326, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.2467 - auc: 0.6156 - loss: 0.4144 - val_accuracy: 0.2087 - val_auc: 0.6133 - val_loss: 0.4197 - learning_rate: 0.0010\nEpoch 5/40\n\nEpoch 5: val_auc improved from 0.61326 to 0.61670, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.2611 - auc: 0.6230 - loss: 0.4094 - val_accuracy: 0.2046 - val_auc: 0.6167 - val_loss: 0.4160 - learning_rate: 0.0010\nEpoch 6/40\n\nEpoch 6: val_auc improved from 0.61670 to 0.61879, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.2700 - auc: 0.6300 - loss: 0.4052 - val_accuracy: 0.1897 - val_auc: 0.6188 - val_loss: 0.4141 - learning_rate: 0.0010\nEpoch 7/40\n\nEpoch 7: val_auc did not improve from 0.61879\n282/282 - 23s - 81ms/step - accuracy: 0.2746 - auc: 0.6410 - loss: 0.3977 - val_accuracy: 0.1838 - val_auc: 0.6166 - val_loss: 0.4163 - learning_rate: 0.0010\nEpoch 8/40\n\nEpoch 8: val_auc did not improve from 0.61879\n282/282 - 23s - 80ms/step - accuracy: 0.2860 - auc: 0.6486 - loss: 0.3918 - val_accuracy: 0.2263 - val_auc: 0.6179 - val_loss: 0.4183 - learning_rate: 0.0010\nEpoch 9/40\n\nEpoch 9: val_auc improved from 0.61879 to 0.62167, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 81ms/step - accuracy: 0.2880 - auc: 0.6546 - loss: 0.3858 - val_accuracy: 0.2196 - val_auc: 0.6217 - val_loss: 0.4226 - learning_rate: 0.0010\nEpoch 10/40\n\nEpoch 10: val_auc did not improve from 0.62167\n\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n282/282 - 23s - 80ms/step - accuracy: 0.2966 - auc: 0.6641 - loss: 0.3792 - val_accuracy: 0.2391 - val_auc: 0.6160 - val_loss: 0.4276 - learning_rate: 0.0010\nEpoch 11/40\n\nEpoch 11: val_auc did not improve from 0.62167\n282/282 - 23s - 80ms/step - accuracy: 0.3026 - auc: 0.6729 - loss: 0.3707 - val_accuracy: 0.2727 - val_auc: 0.6189 - val_loss: 0.4297 - learning_rate: 5.0000e-04\nEpoch 12/40\n\nEpoch 12: val_auc did not improve from 0.62167\n282/282 - 22s - 79ms/step - accuracy: 0.3129 - auc: 0.6799 - loss: 0.3636 - val_accuracy: 0.2738 - val_auc: 0.6146 - val_loss: 0.4373 - learning_rate: 5.0000e-04\nEpoch 13/40\n\nEpoch 13: val_auc did not improve from 0.62167\n282/282 - 23s - 80ms/step - accuracy: 0.3142 - auc: 0.6871 - loss: 0.3571 - val_accuracy: 0.3017 - val_auc: 0.6181 - val_loss: 0.4405 - learning_rate: 5.0000e-04\nEpoch 14/40\n\nEpoch 14: val_auc did not improve from 0.62167\n\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n282/282 - 23s - 80ms/step - accuracy: 0.3218 - auc: 0.6916 - loss: 0.3516 - val_accuracy: 0.2868 - val_auc: 0.6177 - val_loss: 0.4475 - learning_rate: 5.0000e-04\nEpoch 15/40\n\nEpoch 15: val_auc improved from 0.62167 to 0.62316, saving model to /kaggle/working/best_cnn_blstm_model.keras\n282/282 - 23s - 80ms/step - accuracy: 0.3274 - auc: 0.6958 - loss: 0.3472 - val_accuracy: 0.2917 - val_auc: 0.6232 - val_loss: 0.4487 - learning_rate: 2.5000e-04\nEpoch 16/40\n\nEpoch 16: val_auc did not improve from 0.62316\n282/282 - 23s - 81ms/step - accuracy: 0.3283 - auc: 0.7008 - loss: 0.3423 - val_accuracy: 0.2959 - val_auc: 0.6213 - val_loss: 0.4509 - learning_rate: 2.5000e-04\nEpoch 17/40\n\nEpoch 17: val_auc did not improve from 0.62316\n282/282 - 23s - 80ms/step - accuracy: 0.3332 - auc: 0.7049 - loss: 0.3370 - val_accuracy: 0.2957 - val_auc: 0.6215 - val_loss: 0.4535 - learning_rate: 2.5000e-04\nEpoch 18/40\n\nEpoch 18: val_auc did not improve from 0.62316\n\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n282/282 - 23s - 80ms/step - accuracy: 0.3327 - auc: 0.7073 - loss: 0.3339 - val_accuracy: 0.2914 - val_auc: 0.6193 - val_loss: 0.4624 - learning_rate: 2.5000e-04\nEpoch 19/40\n\nEpoch 19: val_auc did not improve from 0.62316\n282/282 - 23s - 81ms/step - accuracy: 0.3363 - auc: 0.7120 - loss: 0.3280 - val_accuracy: 0.2994 - val_auc: 0.6213 - val_loss: 0.4648 - learning_rate: 1.2500e-04\nEpoch 20/40\n\nEpoch 20: val_auc did not improve from 0.62316\n282/282 - 23s - 80ms/step - accuracy: 0.3411 - auc: 0.7134 - loss: 0.3259 - val_accuracy: 0.2887 - val_auc: 0.6203 - val_loss: 0.4661 - learning_rate: 1.2500e-04\nEpoch 21/40\n\nEpoch 21: val_auc did not improve from 0.62316\n282/282 - 23s - 80ms/step - accuracy: 0.3418 - auc: 0.7162 - loss: 0.3216 - val_accuracy: 0.2956 - val_auc: 0.6219 - val_loss: 0.4700 - learning_rate: 1.2500e-04\nEpoch 22/40\n\nEpoch 22: val_auc did not improve from 0.62316\n\nEpoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n282/282 - 23s - 80ms/step - accuracy: 0.3432 - auc: 0.7170 - loss: 0.3200 - val_accuracy: 0.2937 - val_auc: 0.6216 - val_loss: 0.4723 - learning_rate: 1.2500e-04\nEpoch 23/40\n\nEpoch 23: val_auc did not improve from 0.62316\n282/282 - 23s - 80ms/step - accuracy: 0.3476 - auc: 0.7200 - loss: 0.3183 - val_accuracy: 0.2926 - val_auc: 0.6223 - val_loss: 0.4694 - learning_rate: 6.2500e-05\nEpoch 24/40\n\nEpoch 24: val_auc did not improve from 0.62316\n282/282 - 23s - 81ms/step - accuracy: 0.3487 - auc: 0.7204 - loss: 0.3152 - val_accuracy: 0.2916 - val_auc: 0.6218 - val_loss: 0.4715 - learning_rate: 6.2500e-05\nEpoch 25/40\n\nEpoch 25: val_auc did not improve from 0.62316\n282/282 - 23s - 80ms/step - accuracy: 0.3474 - auc: 0.7218 - loss: 0.3150 - val_accuracy: 0.2903 - val_auc: 0.6218 - val_loss: 0.4725 - learning_rate: 6.2500e-05\nEpoch 25: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 5 cnn_blstm - Validation AUC: 0.6949\n\n--- Cross-Validation Results ---\nFold 1: eegnet_tcn - AUC = 0.7271\nFold 2: cnn_blstm - AUC = 0.6974\nFold 3: attention - AUC = 0.7611\nFold 4: eegnet_tcn - AUC = 0.7361\nFold 5: cnn_blstm - AUC = 0.6949\nAverage AUC: 0.7233 ± 0.0249\nBest model from fold 3: attention with AUC 0.7611\n\n=== Ensemble Model Performance ===\nConfusion matrices saved to: /kaggle/working/confusion_matrices.png\n\n===== Detailed Metrics Report =====\nClass                Accuracy   Precision  Recall     F1 Score  \n------------------------------------------------------------\nHandStart            0.9132     0.9299     0.6933     0.7944\nFirstDigitTouch      0.9810     0.9945     0.9280     0.9601\nBothStartLoadPhase   0.9881     0.9882     0.9625     0.9752\nLiftOff              0.9546     0.9267     0.8852     0.9055\nReplace              0.9434     0.9356     0.8255     0.8771\nBothReleased         0.9416     0.9316     0.8253     0.8752\n------------------------------------------------------------\nAverage              0.9537     0.9511     0.8533     0.8979\n\\Validaiton AUC Scores by Class:\nHandStart: 0.9768\nFirstDigitTouch: 0.9990\nBothStartLoadPhase: 0.9994\nLiftOff: 0.9925\nReplace: 0.9889\nBothReleased: 0.9871\nAverage Ensemble AUC: 0.9906\nEnsemble ROC plot saved to: /kaggle/working/ensemble_roc_curves.png\nHistory plot saved to: /kaggle/working/ensemble_training_history.png\n\n=== Final Model Performance ===\nModel type: ensemble\nValidation AUC: 0.9906\n\nTotal execution time: 1h 4m 24s\n\n=== Process Complete ===\n","output_type":"stream"}],"execution_count":1}]}